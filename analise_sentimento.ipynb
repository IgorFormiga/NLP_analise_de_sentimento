{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo deste projeto é a criação de um modelo de Machine Learning de classificação utilizado o processamento de linguagem natural. O modelo irá classificar os comentários em três classes: \"Positivo\", \"Negativo\" e \"Neutro\". O conjunto de comentários negativos possui um alto valor de informação para empresas, podendo ser utilizado como feedback de melhoria e/ou base de dados para análise de causa raiz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from nltk import tokenize, RSLPStemmer, FreqDist, tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.lm import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wordcloud import WordCloud\n",
    "from string import punctuation\n",
    "from time import time\n",
    "\n",
    "from utils.regex_utils import *\n",
    "from utils.stopword_utils import RemoverStopwords\n",
    "from utils.normalize_utils import ProcessoNormalizacao\n",
    "from utils.stemming_utils import ProcessoStemming\n",
    "from utils.features_extract import ExtracaoFeatures\n",
    "from utils.n_grams_utils import ngrams_count\n",
    "from utils.wordcloud_utils import nuvem_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Leitura dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O projeto foi desenvolvido utilizado um conjunto de dados público de e-commerce brasileiro de pedidos feitos na Olist Store, a maior loja de departamentos dos marketplaces brasileiros. A Olist conecta pequenas empresas de todo o Brasil a canais sem complicações e com um único contrato. Esses comerciantes podem vender seus produtos através da Olist Store e enviá-los diretamente aos clientes usando os parceiros de logística da Olist. O dataset possui informações de 100 mil pedidos de 2016 a 2018 feitos em vários marketplaces no Brasil. \n",
    "\n",
    "A base de dados de reviews foi construída a partir compras de produtos por clientes na Olist Store. Assim que o cliente recebe o produto, ou vence a data prevista de entrega, o cliente recebe uma pesquisa de satisfação por e-mail onde pode dar uma nota da experiência de compra e anotar alguns comentários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('order_reviews.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_title</th>\n",
       "      <th>review_comment_message</th>\n",
       "      <th>review_creation_date</th>\n",
       "      <th>review_answer_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
       "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-18 00:00:00</td>\n",
       "      <td>2018-01-18 21:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
       "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-10 00:00:00</td>\n",
       "      <td>2018-03-11 03:05:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
       "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-17 00:00:00</td>\n",
       "      <td>2018-02-18 14:36:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
       "      <td>658677c97b385a9be170737859d3511b</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>2017-04-21 00:00:00</td>\n",
       "      <td>2017-04-21 22:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
       "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>2018-03-02 10:26:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id                          order_id  \\\n",
       "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
       "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
       "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
       "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
       "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
       "\n",
       "   review_score review_comment_title  \\\n",
       "0             4                  NaN   \n",
       "1             5                  NaN   \n",
       "2             5                  NaN   \n",
       "3             5                  NaN   \n",
       "4             5                  NaN   \n",
       "\n",
       "                              review_comment_message review_creation_date  \\\n",
       "0                                                NaN  2018-01-18 00:00:00   \n",
       "1                                                NaN  2018-03-10 00:00:00   \n",
       "2                                                NaN  2018-02-17 00:00:00   \n",
       "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
       "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
       "\n",
       "  review_answer_timestamp  \n",
       "0     2018-01-18 21:46:59  \n",
       "1     2018-03-11 03:05:13  \n",
       "2     2018-02-18 14:36:24  \n",
       "3     2017-04-21 22:02:06  \n",
       "4     2018-03-02 10:26:53  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compreensão de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Analise de dados faltantes (Null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['review_id', 'review_creation_date', 'review_answer_timestamp', 'review_comment_title', 'order_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   review_score            99224 non-null  int64 \n",
      " 1   review_comment_message  40977 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40977, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retirando o valores Null de reviews\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_score                             review_comment_message\n",
       "0             5              Recebi bem antes do prazo estipulado.\n",
       "1             5  Parabéns lojas lannister adorei comprar pela I...\n",
       "2             4  aparelho eficiente. no site a marca do aparelh...\n",
       "3             4    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
       "4             5  Vendedor confiável, produto ok e entrega antes..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Rotulagem dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Criando um datafrem que contem as quantidade de acordo com o score\n",
    "quantidade = pd.DataFrame(dataset['review_score'].value_counts()).sort_index()\n",
    "\n",
    "# plotando o gráfico de barra\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax = sns.barplot(y='review_score', x=quantidade.index, data=quantidade, orient='v', palette='viridis')\n",
    "ax.set_title('Quantidade de comentários por score', fontdict={'fontsize': 20})\n",
    "ax.set(ylabel=None, xlabel=None)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com objetivo de criar um modelo de análise sentimental em uma abordagem de Machine Learning supervisionado, iremos dividir os sentimentos em três classes: negativo, neutro e positivo. O database não possui uma definição explicita sobre a definição de sentimento para cada comentário. Pensando em uma implementação rápida, utilizaremos a coluna \"review_score\" para rotular os dados nas três classes já que ela dá uma uma ideia sobre a satisfação do cliente a respeito da compra.\n",
    "\n",
    "Rotulagem dos dados:\n",
    "- Positivo (1): Compreende os scores de valores 4 e 5\n",
    "- Neutro (0): Compreende o score de valor 3\n",
    "- Negativo (-1): Compreende os scores de valores 1 e 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotulagem dos dados\n",
    "score_map = {\n",
    "    1: -1,\n",
    "    2: -1,\n",
    "    3: 0,\n",
    "    4: 1,\n",
    "    5: 1\n",
    "}\n",
    "\n",
    "dataset['sentiment_label'] = dataset['review_score'].map(score_map)\n",
    "dataset = dataset[['review_score', 'sentiment_label','review_comment_message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_score  sentiment_label  \\\n",
       "0             5                1   \n",
       "1             5                1   \n",
       "2             4                1   \n",
       "3             4                1   \n",
       "4             5                1   \n",
       "\n",
       "                              review_comment_message  \n",
       "0              Recebi bem antes do prazo estipulado.  \n",
       "1  Parabéns lojas lannister adorei comprar pela I...  \n",
       "2  aparelho eficiente. no site a marca do aparelh...  \n",
       "3    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n  \n",
       "4  Vendedor confiável, produto ok e entrega antes...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    26530\n",
       "-1    10890\n",
       " 0     3557\n",
       "Name: sentiment_label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAFUCAYAAAAAtgZ5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsaUlEQVR4nO3dd5wkRf3G8c8XjijhyEFAEITDQBqkRbIiQzAAogjSgpjJs4DyA3VmBAVF+gARFUGEFRUEExIGlAwy4pAOYUBBUImSBCQe1O+P6j3m1t293bvZqe7p5/167Yu7up2dZxWeq63urjLnHCIikn3zhQ4gIiLjo8IWEckJFbaISE6osEVEckKFLSKSEypsEZGcUGGLiOSECltEJCdU2CIiOaHCFhHJCRW2iEhOqLBFRHJChS0ikhMqbBGRnFBhi4jkhApbRCQnVNgiIjmhwhYRyQkVtohITqiwRURyQoUtIpITKmwRkZwobGGb2atmdquZ3WFmvzCzRSf4+pXN7Pz01xuY2Y4df/ZBMzui25lFpNjMORc6QxBm9pxzbrH01+cALedcMpdfax9gY+fcAV2MKCIym8LOsIe5FljLzJY2s1+b2e1mdqOZrQdgZluls/FbzewWM1vczFZPZ+cLAl8Ddk//fHcz28fMTjGzJc3sfjObL/06i5rZP81sgXRWfmP6Xr8ys6UCfv8ikgOFL2wzmwLsAMwA6sAtzrn1gCOBs9NPOwzY3zm3AbAF8MLQ651zLwNfBc51zm3gnDu348/+A9wGbJUOfQBoOOdeSb/2l9L3mgFUJ+2bFJG+UOTCXsTMbgX+DPwDOAPYHBgEcM5dASxjZksC1wOJmR0ETHXOzZzA+5wL7J7++mPAuenXnOqcuzodPwvYch6/HxHpc1NCBwjohXTGPIuZ2Qif55xzx5nZRcCOwI1mti3w4jjf57fAsWa2NFACrgAWm/vYIlJURZ5hj+Qa4OMAZrY18Lhz7hkzW9M5N8M59038jHzasNc9Cyw+0hd0zj0H/Ak4Cfidc+7VdKnkKTPbIv20GLh6pNeLiAwp8gx7JDXgTDO7HXge2DsdP8TMtgFeBe4ELgFW6njdlcAR6RLLsSN83XOBXwBbd4ztDXw/vZ3wPuCTXfsuRKQvFfa2PhGRvNGSiIhITqiwRURyQoUtIpITKuzAzGyqmZ1vZm0zu8vMNjWzmpk92PF05Y7p526WPhl5k5mt1fH6xii3JIpIH9FFx8DM7CzgWufc6elj7osChwDPOee+Pexzfwl8CVgd2N45d6iZnQD8tuMhnL5QLlXnAxbo+JgCzAReaLTq470HXqSv6La+gMxsCfwTjvvArMfcXx5jsvwKsAi+1F8xszWBN2a5rMul6vz4v2DWAJYHluv4Z+fHMsDC+H8nF2CMn/7KpaoDXgKeA55JP/4DPAE8CPxr+EejVX+569+cSI9phh2QmW0AnIa/t3t9oAUcDByOL/Fn8A/qHOqceyr9/O/j9zKJgW8DX3HO/bXX2Ycrl6qrAGunH2/p+Oeb8QUckgMeBx4A/oLfu2UGcEejVX8oZDCRiVBhB2RmGwM3Aps555pmdhK+pE/BF4wDjgZWcs7tO+y1WwI74wv8aPzs+1Dn3KOTnbtcqi4LRMAm6cc78TPkPHoCuCP9uA24Abiz0arrPwzJHBV2QGa2InCjc2719PdbAEc453bq+JzV8Y+0v71jzIAGflOpU/CFvTqwhXPuqG5mLJeqBmyI33FwqKTX6OZ7ZNATwHX4rQquAW5ptOqvho0kojXsoJxzj6T7Y6/jnLsbeC9wp5mt5Jx7OP20XfCzv057AxelyySLAq+lHxM6NWc05VJ1OaCcfmyHX3MukmWAD6UfAM+WS9U/4vd7uajRqt8WLJkUmmbYgaXr0qcDC/L6niInAxvgl0TuBz43VOBpQV8EbOeceyWdlZ8KvAzs4Zy7Z6IZ0guD7wa2Tz82BHSb4Ojux+/C+BvgmkarPpHtdkXmmgq7wMql6ruBPYCPUrxZdLc8BVyML+9LG636s4HzSB9TYRdMuVRdD1/SH8Ove0v3vAj8CvgR8AdduJRuU2EXQLlUXQm/1LIn8LbAcYriH/iThM5stOp/Dx1G+oMKu4+VS9XNgQPxFy5D3wtdVA5/sfJM4PxGq/584DySYyrsPlMuVRfBn5qzP/7CpWTHk8D3gO80WvVJv19e+o8Ku0+US9U18CW9L7BU4DgytpeAnwDfbrTq7dBhJD9U2DlXLlWnAUfhLyTOHziOTIzD36L57Uarntn9YCQ7VNg5VS5V3w58BdgNbZPbD24Cqo1W/ZLQQSS7VNg5Uy5V18EfFvxRVNT96GrgiEarfmPoIJI9KuycKJeqq+L3DNkLLX0Uwa+BIxut+l2hg0h2qLAzrlyqLgx8EX9wQVf2CpHceBU4G79U8s/QYSQ8FXaGlUvV3fB7Xr8pdBYJ6iUgAY7RfdzFpsLOoHKp+g7gJGCb0FkkU/4BVBqt+i9DB5EwVNgZUi5VpwJfBz6H1qlldJcC++mR9+JRYWdEuVTdCX9c2Mqhs0guPI+/WyjR4QrFocIOrFyqLgmcSHoQr8gE3QJ8qtGq3xI6iEw+FXZA5VJ1e+CHwCqhs0iuvYx/iOp4bena31TYAZRL1SXwV/0/FTqL9JUrgL0brfq/QgeRyaHC7rF0y9NzgNVCZ5G+9CTwuUarfn7oINJ9KuweKpeqhwLHocOPZfKdCRzUaNWfCx1EukeF3QPphcUz8QcJiPTK34CPNFr1W0MHke7Q5kGTrFyqrg/8GZW19N5awPXlUnX30EGkOzTDnkTlUvVTwCnAwqGzSOEdBxzVaNVfCx1E5p4KexKUS9UFgFOBT4fOItLhYmDPRqv+n9BBZO6osLssvWXvfOB9obOIjOBu4EONVv3u0EFk4rSG3UXlUnUV4FpU1pJd6wDNcqm6Q+ggMnEq7C5JLy7eCKwXOovIHCwJ/LZcqsahg8jEqLC7oFyqboefWb8xdBaRcZoCnFUuVQ8OHUTGT4U9j8ql6r74k68XD51FZIIMOLFcqh4TOoiMjy46zoNyqXogcHLoHCJd8H1gf932l20q7LmU/ih5YugcIl10HhA3WvWXQweRkamw50K5VK3gd9sT6TeXADurtLNJa9gTVC5VD0NlLf1rB+DccqmqDcoySIU9AeVS9YvA8aFziEyynfF3kKgfMkb/h4xTWtbfDJ1DpEf2BH5QLlUtdBB5nQp7HMql6idRWUvxfBpdWM8UXXScg/TcxQvRoQNSXMc2WvUjQ4cQFfaYyqVqCbgaeEPoLCKBHdZo1U8IHaLoVNijKJeqawB/BFYInUUkA17D3+53YeggRabCHkG5VF0WuB5YO3QWkQx5Dti80arfFjpIUemi4zDlUnUR/Jq1ylpkdosBF5ZL1RVDBykqFfb/+gHwrtAhRDJqVeDX5VJVx94FoMLuUC5V9we0R7DI2CLgx7pHu/dU2KlyqbopMD10DpGc2B34SugQRaOLjkC5VF0euBkdQCAyEa8B72u06leEDlIUhZ9hl0vV+YFzUVmLTNR8wE/SCY/0QOELGzgO2Dp0CJGcWgk4W+vZvVHowi6Xqh8CDgudQyTnysDhoUMUQWHXsNN7SWcAy4bOItIHZgJbNFr1G0MH6WdFnmGfgcpapFumAD8rl6pTQwfpZ4Us7HKp+nlgx9A5RPrM6sCpoUP0s8ItiZRL1TcDt6Md+EQmywcarfrvQofoR4Uq7PRK9pXAVqGziPSxfwFva7Tqz4QO0m+KtiSyPyprkcm2Cv52Wemywsywy6XqqsBdaClEpBccsGWjVb8udJB+UqQZ9gmorEV6xYDTy6XqQqGD9JNCFHa5VH0P8JHQOUQKZh20QVRX9f2SSLlUnQLcBrw1dBaRApoJrNdo1e8KHaQfFGGGfSAqa5FQpgBJ6BD9oq9n2OVSdQXgHmCJ0FlECm7HRqt+SegQedfvM+xvobIWyYIkXZ6UedC3hV0uVTdBx32JZMU04DOhQ+Rd3xY2cAz+1iIRyYZquVRdLHSIPOvLwi6XqpsD7wudQ0RmswLaf36e9GVhA0eHDiAiIzqsXKouFzpEXvVdYacPyWwdOoeIjOgNQCV0iLzqu8IGvhY6gIiMab9yqbpk6BB51FeFXS5Vy8BmoXOIyJiWxO+cKRPUV4WNZtcieXFIuVRdJHSIvOmbwi6XqlsBm4TOISLjshzw6dAh8qZvChs4KHQAEZmQw8ql6gKhQ+RJXxR2uVR9E/Ch0DlEZEJWA/YKHSJP+qKwgQOA+UOHEJEJ0y1+E5D73frKpeob8Id+Tg0cRUTmzqaNVv3G0CHyoB9m2DEqa5E8+1zoAHmR6xl2uVQ14C/AuqGziMhcewFYudGqPx06SNblfYa9DSprkbxbBG2FPC55L+xPhA4gIl3x2dAB8iC3SyLpU1KPAouHziIiXbFZo1W/IXSILMvzDPtDqKxF+olm2XOQ58LWDfci/WWXcqm6UOgQWZbLwi6XqssC5dA5RKSrlgC2Cx0iy3JZ2MDugE5gFuk/u4UOkGV5LWwth4j0pw9qQ6jR5a6wy6XqqsC7QucQkUkxFdg2dIisyl1hAzuFDiAik0rLIqPIY2HvGDqAiEyqnculqq5RjSBXhZ3e8vOe0DlEZFItDWwdOkQW5aqwga2AN4QOISKT7n2hA2RR3gpbyyEixfDe0AGySIUtIlm0YblUXSp0iKzJTWGXS9W1gLeEziEiPTEfWsf+H7kpbPQjkkjR6L/5YfJU2JuGDiAiPaU7woZRYYtIVq1bLlVXCh0iS3JR2OVSdRlg7dA5RKTntgkdIEtyUdho7xCRoto4dIAsUWGLSJZtFDpAluSlsLV+LVJMG5RLVQsdIisyX9jlUnU+YJPQOUQkiCWBN4cOkRWZL2z8xUYdtitSXBuGDpAVeSjsdUMHEJGgtI6dykNhTwsdQESC0gw7pcIWkaxTYadU2CKSdSuUS1VdxyIfhb1O6AAiEtwaoQNkQaYLu1yqroi/rUdEim310AGyINOFjZZDRMTTDJvsF7YOLBARUGED2S/sVUIHEJFMUGGT/cJeOXQAEcmE1UMHyAIVtojkgWbYZL+wddqEiAAsXi5VFw0dIrSsF/byoQOISGZMDR0gtKwX9rKhA4hIZkwNHSC0zBZ2+ijqQqFziEhmLBU6QGiZLWw0uxaR2U0NHSC0LBd24S8wiMhsNMMOHWAMWg4RkU5TQwcITYUtInmhGXboAGNQYYtIp8VCBwhNhS0ieTF/6AChqbBFJC+y3Fc9keX/AVTYItKp8DPsKaEDjGHB0AEkEx4HjgReCx1EgvtL6AChZbmwXegAEpwD4karfmnoICJZkOUlkRdCB5DgjlNZi7wuyzNsFXaxXQN8ZfjgtNr0+YHPAG/veSLJmpPatcpfQ4foJRW2ZNG/gT0arfqrw/+gXau8Oq02/QzgEKAKvKHH2SQ7zgMKVdhZXhJ5PnQACcIBezVa9Yc6B6M42T2KkzJAu1Z5pV2rHA9MA84PkFGy4X/+Qu93WS5szbCL6RuNVv2yzoEoTtYDfgxcGsXJ+VGcrALQrlX+1a5VPgJsD/yt50klNBV2hmiGXTxX45c5ZoniZDH8j74Lp0MfBu6K4uTwKE6mALRrlQZ+TfurwIu9iyuBqbAzRDPsYnmMkdetfwCsM2xsMeBbwK1RnGwJ0K5VXmrXKkcDbwMumuywkgnPhQ7Qa1ku7GdCB5CeeQ2/bv1w52AUJ58F9hzjdW8Dro7iZDCKkxUA2rXKfe1a5f3AzsADk5RXsuGp0AF6LbOF3WjV/0sB/wYtqG80WvXLOweiOFkfOGmcr98LuDuKkwOiOJkfoF2r/AZ4K3As8HI3w0pmPBk6QK9ltrBTD835UyTnrgJqnQNRnCzO7OvW47Ek8B3gpihOIoB2rfJ8u1Y5ElgP+EM3wkpmPN+uVQr3F7EKW0J6lJHXrU8D1p7Lr7kh8McoTk6L4mRpgHatcne7VtkW2AN4eMxXS14UbnYN2S9s/cfVv4bWrR/pHIzi5HPAx+bxaxv+ach7ojj5dBQnBtCuVX6Ov3f7RAp4h0GfKdz6NWS/sDXD7l/HNFr133cORHGyAb5Mu2UZ4IfA9enXpl2rPNOuVSrARsD1XXwv6S3NsDNIhd2frgTqnQNzuW49XpsCf47i5OQoTpYAaNcqtwNbAPviH4WXfNEMO4NU2P3nUWDPRqs+fH/rHwJvmcT3nR84EH83yccB2rWKa9cqZ+Lv8/4+2nM7TzTDzqAHQweQrnoNX9bD162/AOzeowwrAj+J4uSKKE7WBWjXKk+1a5UvAO8CWj3KIfPmH6EDhJD1wm6HDiBddXSjVb+icyCKkw2B6QGybAPcFsXJN6M4eQNAu1a5CdgE2A94OkAmGb9C7h2T6cJutOr/xh8RJfn3B+BrnQPpevJ5hDu/cwHgi/i9SXYFaNcqr7Vrle/hl0nOQicfZdW9oQOEkOnCTt0ZOoDMs0eAj4+ybr1WgDzDrQpcEMXJxVGcrAnQrlUea9cq+wBbAXeEDCcjUmFnVOEP3sy5oXXrRzsHozjZD/homEij2gG4I4qTWhQnCwO0a5Vr8Q/jHIq2SsiKZ9u1SiHv7MlDYWuGnW/1Rqt+ZedAFCcbAUmgPHOyMH6L1zuiONkBoF2rzGzXKgn+oZvzQoYToKCza1Bhy+T6PXBM50AG1q3Ha03g4ihOfhnFyWoA7VrlwXatsjuwHXBP0HTFVsgLjqDClsnzMCOvW5+BL8O82AV/UfKIKE4WAGjXKpcD7wC+jPZtD0Ez7KxK79l9InQOmZBX8evWj3UORnFyALBbmEjzZFH8Nq23RXGyDUC7Vnm5Xat8Hb+F64UhwxVQoQ7e7ZT5wk41QweQCak3WvWrOgeiOCkB3w4Tp2vWBa6I4uScKE5WBGjXKve3a5UPAh8E7g8ZrkBuDh0glLwUtjbpyY/Lga93DkRxsiT5WLcerz3xj7gf3HFgwoX42fYx6MCEyfQiMCN0iFBU2NJNDzH6uvWbA+SZTEvgdxb8cxQnmwK0a5UX2rXKV/Dr25eP8VqZe7e2a5WZoUOEkpfC/hPwSugQMqahdevZ7o+N4uRA/Enn/WoD/PatZ0RxsixAu1a5p12rbIffH0X74XTXTaEDhJSLwm606i8At4TOIWOqNlr1qzsHojjZmPyvW4+H4bdpvTuKk892HJhwHv7e7ROAws4Ku0yFnRNaFsmuy4BvdA50rFsvGCRRGEsDP8AfUbYRQLtWea5dqxyGf1ry2pDh+sSfQgcIKU+FfV3oADKih/BHfQ3fJOlHwBoB8mRBhD8M+JQoTqYCtGuVO9q1ypbA3sBjY71YRvUfCv7AUp4KWzPs7HkVf4ju8HXrg4Fdw0TKjPmA/YF2FCfx0GC7VjkbvxPgqejAhIlqtWuVQu+eaM7l5/svl6q3AuuHziGzHNVo1YcvhbwT/9NQkZZCxuNqYP/m4MCszcym1aaX8MW9SbBU+fL1dq3y5dAhQsrTDBv0RFmWXIp/+m+W9Mf/oq1bj9dWwK1RnBwfxcliAO1apYU/b/LzFPTIqwn6Q+gAoamwZW48CMQjrFufCaze+zi5MQU4DL83yW4w68CEH+CXSX6EDkwYzfNoWTR3SyKG31RohdBZCuxVYOtGqz7bReAoTg4hzFFfeXYZcEBzcGDW3hjTatPfDXwPWC9YqmxqtGuV7UOHCC1XM+x0RndR6BwF9+URynoT4FuB8uTZdsCMKE6OjuJkEYB2rXIDsBFQAZ4NGS5jRn1y1MwONrM7zOwvZnZIOvZNM7vdzM7u+LzYzA7uQdZJk6vCTv0udIACuwT4ZudAFCdLAefiz0eUiVsIv03rX6I4eT9Au1Z5tV2rnIhfJvl5wGxZcvFIg2b2duAz+Au36wPvN7P1gXc759YD5jezd5jZIsA++Iu8uZXHwr4MeCl0iAL6F/AJrVtPmjWAC6M4+U0UJ28CaNcqD7drlT2A9wLtoOnC+nu7VrlrlD9bF7jROfe8c24m/m6cnYEFzcyARfDbWhwOnOycy/UWF7kr7Ear/l/gitA5CmYm8LFGqz7bCfZRnAwAHwoTqW99ELgzipMjozhZEKBdq1yBnz3+H/7iW9GMtQx6B7ClmS1jZosCOwLLAhfgt7P4O/6Bm3c6534znjczM2dmJ3T8/jAzq81NcDObamb7zc1rR5K7wk79LHSAgvlyo1Wf7Qp9FCcRcFygPP1uUfwWtbdHcfJemHVgwnH4LVx/HTBbCKMWtnPuLvwy3eX4W01vA2Y6577lnNvAOXcocDTwVTP7tJmdZ2Zzupf7JWBXM1u2C9mnAiMWtpnNP9EvltfC/iU6wbpXLmLYBUWtW/fMOsDvozj5eRQnKwO0a5UH2rXKLsBOwH1B0/XGk8zh/mvn3BnOuY2cc1umnz/rrhsz2zD95T3AJ5xzHwXebmZvGeNLzgROw1/4nY2ZLWdmF5jZTenHZul4zcwO6/i8O8xsdfykZk0zu9XMjjezrc3sSjP7KTDDzBY2szPNbIaZ3WJm24z1veaysNNlkQtC5yiAfwJ7j7BufRbwpgB5imp3/CPulShOpgC0a5WLgbcBX6O/r+n8ol2rjLnubGbLp/9cDb8lQudP4EcDX8VPLoZmtK/hf4oZy3eBj5vZksPGTwKmO+feid82+PQ5fJ0jgHvT2f7h6dgmwFHOubfity/AOfcOYA/gLDNbeLQvlsvCTp0VOkCfG1q3nu08zShODgU+ECZSoS0OJEAripPNANq1yovtWqUKvB2/HNCPzhnH51xgZnfiH6zb3zn3FICZ7Qzc5Jx7yDn3NPBHM5sBOOfcbWN9QefcM8DZwEHD/mhb4BQzuxX4LbCEmS0+ge8H4E/Oub+nv94cGEzfsw08AKw92gunTPCNsuQq/Denmd7kOLLRqt/QORDFybsY9ji69Nx6wLVRnJwFfLE5OPDvdq3yN2CHabXpH8afgrNKyIBd9A/GsUunc26LUcZ/Tcd6v3PuMPyTpuN1Iv78yDM7xuYDNnXOvdD5iWY2k9knwKPOkoH/dr50AnnyO8NOf0z/Segcfep3DDt4IIqTpdG6dVYY/p7iu6M4+XwUJ/MBtGuVC/C3uR1Pf5zQ9LOQu/M5557E743zqY7hy4ADhn5jZhukv7wf/8ATZrYRr28t/Cz+p6PRXAN8PH3d2sBqwN2jfXJuCzt19pw/RSbof9at0xNUzsL/yyTZsRT+MfZmerrP0IEJX8QfXXb1GK/Ng/Esh0y2E/C3CQ45CNg4fYryTvzGXeCvqS2dLpV8gXTfbufcE8D16UXI40f4+qfiH+6ZgZ8Q7eOcG/WaRK72EhlJuVS9DtgsdI4+8QqwVaNV/2PnYBQnh6NHz7PuNfydDUc2BweeGhqcVpu+F/6npbztvzOjXatoP5Vh8j7DBn81V7rjyBHKelOGHf8lmTQffrZ3dxQn+3ScK/kT/O2Bp+A37sqLLMyuM6cfCvt8/DFVMm8uxP/4N0sUJ8vgf0zL88XpolkOf5HsmihO3gHQrlX+065VDgTeCTRDhhunmej61IhyvyQCUC5Vv4y/31LmzgPAho1WfdaP0ukM7UL8AxqSTzOBk4Fac3DgWYBptemGv4h2HLBMwGxjObddq3wsdIgs6ocZNviTql+Y42fJSF7B32/91LDxw1FZ590UYAD/0M3uAO1axbVrldPxyySnk80DE04KHSCr+mKGDVAuVb/H61dsZfwObbTqSedA+mDGVWgppN/8Hn+u5KyTx6fVpr8Lf6fChqO+qrduatcqOuNyFP0ywwb/FJhOoZ6Y345Q1svg92BWWfefbfEHJny948CEG/Fr2wfhd7ULTbPrMfRNYTda9b8C49o+UQC/br1P50C6bn02/fOknPyvBYEj8Vu4fhBmHZjwHWAaYe/OeBj/oIqMom8KO/X10AFy4hVg9xHWrb+I309Y+t/qwG+iOLkwipM1ANq1yiPtWmUvYBvgzgCZvjenjZ6Krq8Ku9Gqt/Bbr8rYvtRo1We7vSuKk82BYwLlkXDejz+e7CtRnCwE0K5VrsI/KfklZt/3YjK9hL95QMbQNxcdh5RL1XXxp1D01V9GXfTrRqu+S+dAFCfLArcCbwySSLLir/iLkrMOvJ1Wm74qfhOkXSf5vU9v1yqfmeT3yL2+K2yAcql6FvCJ0Dky6H78/dZPDw2k69YXA9sHyiTZ8wug0hwceHBoYFpt+vbAd4C1JuH9Xgbe0q5V/jEJX7uv9OsstIr/l0BeN7Ru/fSw8SNQWcvsPoK/d/vQjgMTLsXvu10DXuzy+52msh6fvpxhA5RL1e8yyllqBXVIo1Wf7ZapKE62AK7k9ZM4RIa7A9ivOThw7dDAtNr0N+Nn2924QP0C8OZ2rfJIF75W3+vnwl4RuJc5HwVUBL9qtOqzrUFGcbIc/lRprVvLeAwChzUHBx4bGphWm74Lfn17XrbdPT7dDlbGoV+XRGi06o/g/2Uqur8D+3YOpOvWg6isZfxi/E6A+3ccmPAr/IEJ32TuDkx4Nn2tjFPfFnbqG/gN+YvqZeCjI6xb/x9Q7n0cybmp+G1a/xTFySYA7Vrl+XatcgSwPn55bSJObNcqT8z502RI3y6JDCmXqrtS3BPWD2606id3DkRxsiVwBVq3lnnzGn7zqP9rDg48OTQ4rTZ9T/w2vSvO4fVPAWu0a5UsPA6fG31f2ADlUvViYIfQOXrsgkarvlvnQBQny+PXrVcOE0n60OP4B2zObA4OOIBptelLAF/Dn3042sTg8Hat8u1R/kxG0e9LIkMOpPu3ImXZfcx+cCjpuuNPUFlLdy0LnAFcF8XJ+gDtWuWZdq1yCFACbhjhNW20ydNcKURhN1r1eynOxY2hdevhP2oeCbwvQB4phncDrShOToziZAmAdq1yG7A5fvLweMfnHqQ9Q+ZOIZZEAMql6sL4e0rXDJ1lkh3YaNVP6RyI4mRr/F7IWreWXngYOLQ5OPCzoYFptelLA8cCy7Rrld1GfaWMqTCFDVAuVcvApaFzTKLzG636RzoH0nXrW4GVgiSSIrsCvzdJe2hgWm36fO1aRfvWz6VCFTZAuVT9AfDZ0Dkmwb3ARo1W/ZmhgXTd+lK0FCLhvIK/a+To5uDA86HD5F0h1rCHGcDvStZPXsKvWz8zbPwoVNYS1gL4gzIWDJyjLxSusBut+n/xT229GjpLFx3aaNVv7hyI4mQb/EY9IqEd3BwceDp0iH5QuMIGSDfv/0boHF1yXqNV/27nQBQnKwA/paD//0qmXNQcHNCxX11S5P+gvwbcFDrEPPobMNum7+m69TnM+Ukzkcn2X2D/0CH6SWELu9GqzwT2AvJ6IWS0deuvAO8NkEdkuK82BwceCB2inxS2sAEarfo9wCGhc8ylSqNVv6VzIIqT9wBfDZRHpFMLPc3YdYW7rW8k5VL1NIYtLWTcuY1W/WOdA1GcrIi/33qFIIlEXvcMUGoODvwtdJB+U+gZdocDgOYcPysbxlq3VllLFuyrsp4cKmyg0aq/DHwYeDR0ljl4EfhIo1V/dtj4V4H3BMgjMtxJzcGBom5nPOlU2KlGq/4g/vDRLG9KU2m06rd2DkRx8l78hUaR0JrA4aFD9DOtYQ9TLlUPwB8wmjU/b7Tqe3QOaN1aMuRJYMPm4IBOP59EmmEPk+509+PQOYa5h2H7n0RxMj/+4RiVtYTmgFhlPflU2CP7HH470ix4EX+/9fB16yqwTYA8IsMd1xwcuDh0iCJQYY8gvQi5K3DznD63Bw5utOq3dQ5EcbItfmMnkdCuQtdQekZr2GMol6rLA9cDawWK8NNGq/7xzoEoTlbCr1svHySRyOsewa9bPxI6SFFohj2GRqv+GFAmzO1+9+CXZmbpWLdWWUtorwJ7qKx7S4U9B41W/T78ievD15An0wv4+62fGzZeA7buYQ6R0RzVHBy4KnSIolFhj0O6Z8fO+ANue+HgRqt+e+dAFCfb4Q/SFQktaQ4OFOVQ60zRGvYElEvVnYALgIUm8W3OabTqe3UORHGyMn7derlJfF+R8TijOTjw6dAhikoz7AlotOoXAR/AL1lMhjYjr1v/DJW1hHce/Xkeam6osCeo0apfDuyE35y9m17A3289/Ot+Ddiyy+8lMlGXAHs1Bwd04nlAWhKZS+VSdXPgYmDxLn3JTzda9TM6B9J160sB69J7iMyNa4Fyc3Bgsn6ylHFSYc+Dcqka4Qt16jx+qcFGq/6JzoEoTt4I3IKWQiSsFvCe5uDA8JONJAAticyD9DDf9wKPz8OXaQNf6BzQurVkxF3A9irr7FBhz6NGq34z8C78gy4T9Tz+fuvh69ZHA1vMazaReXA/8L7m4MC8TEaky1TYXdBo1e8FNgWunuBLD2y06nd0DkRxsj1wRLeyicyFh4Ftm4MDD4YOIrNTYXdJo1V/EtgOOHucLzm70ar/qHMgXbceRBcZJZyHge2agwP3hg4i/0uF3UWNVv3lRqu+N373srGu5t4F7Nc5EMXJFODnwLKTl1BkTDOAqDk4cMccP1OCUGFPgkarfgywJ/DSCH882rr1McDmk51NZBSXAZs3Bwf+GTqIjE6FPUkarfrPga2A4f8B7N9o1f/SORDFyQ7AF3uVTWSYHwI76W6Q7NN92JOsXKouC5yDX98+q9Gq79P551GcrILfJ2SZnoeTonPAkc3BgeNCB5Hx0Qx7kjVa9cfx27MexOjr1ipr6bUX8ftZq6xzRDPsgKI4+SZaCpHeexz4UHNw4IbQQWRiVNiBRHGyE3AhuoVPeuuvwI7NwYG/hQ4iE6fCDiCKk1Xx+4RoKUR66Tpg5+bgwBOhg8jc0Rp2j2ndWgI5Hf/0oso6x6aEDlBAHwXeHTqEFMbTwGebgwO/CB1E5p1m2D3WHBz4KbAv3T8AQWS464D1Vdb9Q4UdQHNw4ExgI+Dm0FmkL70K1ICtm4MD/wicRbpIFx0DiuJkQeBYoILuFpHuuBfYuzk4cH3oINJ9KuwMiOKkjH88eNXQWSS3HPAd4P+agwPPhw4jk0OFnRFRnLwB+DIwACwYOI7ky33Avs3BgYnuxy45o8LOmChO1sbPlLYLnUUyzwGnAl9qDg7oInYBqLAzKoqTDwPT0TKJjKwJHKq16mJRYWdYFCeL4pdJDkXLJOLdh1+nPi90EOk9FXYOpMskJwPl0FkkmCfxhzOf2hwceDl0GAlDhZ0jUZzsil8mWS10FumZl/B/WX+jOTjwdOAsEpgKO2fSZZIjgIOBJQLHkcnjgJ8CRzUHBx4IHUayQYWdU1GcLAl8HjgEWDFsGumyK4HDm4MDrdBBJFtU2DkXxclCwCeAw4G3BI4j8+Y2/Iz6otBBJJtU2H0iipP5gF2BLwEbB44j4zcT+BVwSnNw4JrQYSTbVNh9KIqT9+CLWw/fZNejwGnA95uDAw+FDiP5oMLuY1GcbIgv7t2A+QPHEe8G4LvA+bo9TyZKhV0AUZy8Gb8H98eANQPHKaIXgJ/hlz1uCR1G8kuFXTBRnGwM7IE/+WaVwHH63d+B7wFnNAcHngwdRvJPhV1QUZwYsDl+1r0bsHzYRH3jTuC36UezOTjwWuA80kdU2EIUJ/MD78GX9y7AUmET5cpM4FrSkm4ODtwXOI/0MRW2zCY9BacM7I6/y2S5sIky6T/AJfiSvkSPjEuvqLBlVOmyyduArYCt038WtcD/DlyIL+lrmoMDrwTOIwWkwpZxSwv8rcCWQJR+rEP/nUf5LNAC/jT00Rwc+GfYSCIqbJlH6Z4m7wQ2wRf4O/CHLkwJmWsCHgHuAGYAtwM3AXfpYqFkkQpbui69iLky8CZg9RH+uRqwUA+iOOAp4LGOj0eBe/AFPaM5OPB4D3KIdIUKW3ouXVpZkdcLfFVgEWCBjo8p4/j1TODfvF7Ejw37+HdzcGBmj74tkUmnwhYRyYn5QgcQEZHxUWGLiOSECltEJCdU2CIiOaHCFhHJCRW2FIqZrWpmV5rZXWb2FzM7OB0/18xuTT/uN7Nb0/HNzOx2M7vJzNZKx6aaWcPM+u0JT8m4vDyNJtItM4FDnXM3m9niQMvMLnfO7T70CWZ2An6DJ4BDgQ/j7xf/Qvr7rwDfcLonVnpMhS2F4px7GHg4/fWzZnYX8Eb8Ptaks+aP4rebBXgF/1DPosArZrYm8Ebn3NW9zi6iwpbCMrPVgQ2BZsfwFsCjzrm/pr8/Fn9Y7gtADHwbP8MW6TkVthSSmS0GXAAc4px7puOP9sCfvwiAc+5W4F3pa7YEHvK/tHPxs+9DnXOP9iq3FJseTZfCMbMFgN8BDedc0jE+BXgQKDnn/jXsNQY08Ac7nAIcjV/X3sI5d1SPokvB6S4RKZS0eM8A7uos69S2QHt4Waf2Bi5yzj2FX89+Lf1YdDLzinTSkogUzWb4tegZQ7fuAUc65y7Gn2n5s+EvMLNF8YW9XTqU4JdTXsYvoYj0hJZERERyQksiIiI5ocIWEckJFbaISE6osEVEckKFLTIHZubS/UWGfn+YmdUm4X2OHPb7G7r9HpJvKmyROXsJ2NXMlp3k95mtsJ1z757k95OcUWGLzNlM/H4ileF/YGbLmdkF6farN5nZZh3jl5vZzWb2AzN7YKjwzezXZtZKt3f9bDp2HLBIur3rOenYc+k/zzWzHTve88dm9mEzW9jMzjSzGWZ2i5ltM+n/S0hQug9bZA7S4lwZuB1YH/gMsJhzrmZmPwVOdc5dZ2ar4R93X9fMTgEedM4da2bbA5cAyznnHjezpZ1zT5rZIsBNwFbOuSfM7Dnn3GKd7+ucW8zMdgF2ds7tbWYLAvcCawP7AW93zn3SzKYBlwFrO+de7Nn/ONJTetJRZBycc8+Y2dnAQfid+4ZsC7y14yyDJdJ9tjcHdklfe6mZPdXxmoPSEgZYFXgL8MQYb38JcLKZLQRsD1zjnHvBzDYHvpO+R9vMHsAX+e3z8K1KhqmwRcbvROBm4MyOsfmATZ1znSU+tGfJ/zCzrfElv6lz7nkzuwpYeKw3dc69mH5eGb/51NDj8zrxpmC0hi0yTs65J4HzgE91DF8GHDD0GzPbIP3ldfiDEDCz7YCl0vElgafSsp5GunVr6pV0J8GR/Bz4JH6/7kY6dg3w8fQ91gZWA+6em+9N8kGFLTIxJwCdd4scBGycnvt4J/D5dLwObGdmNwM74E+5eRa4FJhiZrfjt2i9seNrnQbcPnTRcZjLgC2B3zvnXk7HTgXmN7MZwLnAPs65l7rxTUo26aKjyCRI15tfdc7NNLNNge855zYIHEtyTmvYIpNjNeA8M5sPvw3rZwLnkT6gGbaISE5oDVtEJCdU2CIiOaHCFhHJCRW2iEhOqLBFRHJChS0ikhMqbBGRnPh/X5LgVUNmhMkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment = pd.DataFrame(dataset['sentiment_label'].value_counts())\n",
    "labels = ['Positivo', 'Negativo', 'Neutro']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = sns.color_palette('viridis')\n",
    "ax.pie(sentiment['sentiment_label'],labels= labels,autopct='%1.0f%%', pctdistance=1.1, labeldistance=1.2, explode = [0.02, 0.02, 0.02], colors=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Criando uma BaseLine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos definir uma baseline para a acurácia de modelo de classificação de sentimos supervisionado. A baseline é um modelo simples de previsão que atua como referência para futuros modelos de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Bag of Words: criando representações da linguagem humana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40977, 50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vetorizando as 50 palavras com mais ocorrência da coluna \"review_comment_message\"\n",
    "vetorizar = CountVectorizer(max_features=50)\n",
    "bag_of_words = vetorizar.fit_transform(dataset['review_comment_message'])\n",
    "bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ainda' 'antes' 'as' 'até' 'bem' 'bom' 'chegou' 'com' 'como' 'compra'\n",
      " 'comprei' 'da' 'de' 'dentro' 'do' 'em' 'entrega' 'entregue' 'estou' 'eu'\n",
      " 'excelente' 'foi' 'gostei' 'loja' 'mais' 'mas' 'me' 'meu' 'minha' 'muito'\n",
      " 'na' 'no' 'não' 'os' 'para' 'por' 'prazo' 'produto' 'qualidade' 'que'\n",
      " 'recebi' 'recomendo' 'rápida' 'super' 'só' 'tudo' 'um' 'uma' 'veio'\n",
      " 'ótimo']\n"
     ]
    }
   ],
   "source": [
    "# Visualização das 50 palavras com mais ocorrência\n",
    "print(vetorizar.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Modelo: LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     8745\n",
       "2     2145\n",
       "3     3557\n",
       "4     5976\n",
       "5    20554\n",
       "Name: review_score, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificar a proporção do review score\n",
    "dataset.review_score.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:[0.7933963  0.79874076 0.79976572]\n",
      "Média: 0.7973009249090954\n",
      "Desvio Padrão: 0.002792518176023985\n"
     ]
    }
   ],
   "source": [
    "regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial')\n",
    "scores = cross_val_score(regressao_logistica, bag_of_words, dataset['sentiment_label'], cv=3, scoring=\"accuracy\")\n",
    "print(f'Scores:{np.sort(scores)}')\n",
    "print(f'Média: {scores.mean()}')\n",
    "print(f'Desvio Padrão: {scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline de trasformação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será utilizado a classe Pipeline do Scikit Learn para executar uma preparação dos textos de cada comentário de forma automática, deixando pronto para treinamento e previsão do rótulo de sentimento. As etapas do pipeline são:\n",
    "\n",
    "- Remoção das expressões regulares: sabendo que os dados são fruto de comentários da internet, será necessário lidar com algumas expressões regulares. Iremos realizar o pré-processamento dos dados, substituído as expressões regulares por termos que as caracterizem de forma simples;\n",
    "\n",
    "- Remoção de StopWords: As stopwords são palavras que não apresentam relevância em determinado contexto e podem ser removidas sem perda semântica da frase;\n",
    "\n",
    "- Normalização dos comentários: pega os dados Unicode e tenta representá-los em caracteres ASCII (ou seja, os caracteres universalmente exibíveis entre 0x00 e 0x7F), onde os compromissos assumidos ao mapear entre dois conjuntos de caracteres são escolhidos para estar perto do que um humano com um teclado americano escolheria;\n",
    "\n",
    "- Stemming: Stemming é a técnica que transforma as flexões de uma palavra em um núcleo comum (tronco).  Essa técnica normaliza as palavras de forma a evitar suas flexões e derivações. Existem diversos algoritmos para realizar a “stemmização\", seja em Português, sejam em outros idiomas;\n",
    "\n",
    "- Extração de features: A extração de features de texto envolve resumir automaticamente o texto e encontrar palavras importantes. A extração de palavras poderá ser feita de duas formas:\n",
    "    - CountVectorizer: converte uma coleção de documentos de texto em uma matriz de contagens de token, ou seja, produz uma representação esparsa das contagens de frequência das palavras ao longo de todo o dataset;\n",
    "    - TF-IDF (Term Frequency-Inverse Document Frequency): é uma medida estatística que tem o intuito de indicar a importância de uma palavra de um documento em relação a uma coleção de documentos ou em um corpus linguístico.  O TF-IDF irá contar a frequência das palavras e atribui pesos as mesmas, ponderando-as em todo o dataset. Se uma palavra aparece muitas vezes, ela perde o poder de diferenciação, logo, possuirá um peso menor.\n",
    "\n",
    "\n",
    "Todas as etapas do Pipeline foram modularizadas no diretório utils para tornar o programa mais \"limpo\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Analisando os Hiperparâmetros da vetorização (TfidfVectorizer) do Pepiline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1. N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos que estávamos utilizando até agora (bag of words), não gera um valor que preserve a sequência de palavras. O N-grams considera essencialmente uma sequência de palavras que aparecem na mesma \"janela\" ao mesmo tempo. Iremos testar modelos que com a utilização de N-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score para n-grams (1, 2): 0.8399219131283553\n",
      "Score para n-grams (2, 2): 0.8035627135187896\n",
      "Score para n-grams (2, 3): 0.7986822840409956\n"
     ]
    }
   ],
   "source": [
    "# lista de n-grams\n",
    "ngram_range = [(1,2), (2,2), (2,3)]\n",
    "\n",
    "regex_transformers = {\n",
    "    'datas': re_dates,\n",
    "    'valores_dinheiro': re_money,\n",
    "    'numeros': re_numbers,\n",
    "    'negacoes': re_negation,\n",
    "    'caracteres_especiais': re_special_chars,\n",
    "    'espacos_branco': re_whitespaces\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for ngram in ngram_range:\n",
    "    vectorizer = TfidfVectorizer(max_features=300, ngram_range=ngram)\n",
    "\n",
    "    # Criando o Pipeline\n",
    "    text_pipeline = Pipeline([\n",
    "        ('regex', RemoverRegex(regex_transformers)),\n",
    "        ('stopwords', RemoverStopwords(stopwords.words('portuguese'))),\n",
    "        ('normalization', ProcessoNormalizacao()),\n",
    "        ('stemming', ProcessoStemming(RSLPStemmer())),\n",
    "        ('text_features', ExtracaoFeatures(vectorizer))\n",
    "    ])\n",
    "\n",
    "    # Dfinido X e y \n",
    "    comentarios = dataset['review_comment_message'].dropna().index\n",
    "    score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "\n",
    "    # Dfinido X e y \n",
    "    X = list(dataset['review_comment_message'][comentarios].values)\n",
    "    y = score.values\n",
    "\n",
    "    # Aplicando o pipeline\n",
    "    X_processed = text_pipeline.fit_transform(X)\n",
    "\n",
    "    # Dividindo os dados em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=.20, stratify=dataset['sentiment_label'], random_state=42)\n",
    "\n",
    "    #Criação do modelo\n",
    "    regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial', random_state=42)\n",
    "    regressao_logistica.fit(X_train, y_train)\n",
    "    print(f'Score para n-grams {ngram}: {regressao_logistica.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para todos os intervalos de n-grams calculados ocorreu acarretou em piora do modelo de classificação. Logo, não há razões para utilização dos n-grams no modelo de predição, já que sua utilização acarreta no aumento de complexidade do modelo, mas não aumenta sua acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2. Analisando o max_features, min_df e max_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_features: O hiperparâmetro considera apenas as principais features (palavras ou conjunto de palavras) ordenados por frequência de termo em todo o corpus.\n",
    "- min_df: O hiperparâmetro define um limite para ignorar os termos que tenham uma frequência de documento estritamente inferior ao limite fornecido.\n",
    "- max_df: O hiperparâmetro define um limite para ignorar os termos que têm uma frequência de documento estritamente superior ao limite determinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dfinido X e y \n",
    "comentarios = dataset['review_comment_message'].dropna().index\n",
    "score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "\n",
    "# Dfinido X e y \n",
    "X = list(dataset['review_comment_message'][comentarios].values)\n",
    "y = score.values\n",
    "\n",
    "regex_transformers = {\n",
    "    'datas': re_dates,\n",
    "    'valores_dinheiro': re_money,\n",
    "    'numeros': re_numbers,\n",
    "    'negacoes': re_negation,\n",
    "    'caracteres_especiais': re_special_chars,\n",
    "    'espacos_branco': re_whitespaces\n",
    "}\n",
    "\n",
    "# Criando o Pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('regex', RemoverRegex(regex_transformers)),\n",
    "    ('stopwords', RemoverStopwords(stopwords.words('portuguese'))),\n",
    "    ('normalization', ProcessoNormalizacao()),\n",
    "    ('stemming', ProcessoStemming(RSLPStemmer()))\n",
    "    ])\n",
    "\n",
    "# Aplicando o pipeline\n",
    "X_processed = text_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para verificar a acuracia dos melhores valores de hiperparamentros\n",
    "def hiperparamentros_tfidfVectorizer(max_features, min_df, max_df):\n",
    "    col=['max_features', 'min_df', 'max_df', 'score']\n",
    "    list = []\n",
    "    for maxfeatures in max_features:\n",
    "        for mindf in min_df:\n",
    "            for maxdf in max_df:\n",
    "                vectorizer = TfidfVectorizer(max_features=maxfeatures, min_df=mindf, max_df=maxdf)\n",
    "\n",
    "                X = vectorizer.fit_transform(X_processed)\n",
    "\n",
    "                # Dividindo os dados em treino e teste\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20, stratify=dataset['sentiment_label'], random_state=42)\n",
    "\n",
    "                #Criação do modelo\n",
    "                regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial', random_state=42)\n",
    "                regressao_logistica.fit(X_train, y_train)\n",
    "                score = regressao_logistica.score(X_test, y_test)\n",
    "                list.append([maxfeatures, mindf, maxdf, score])\n",
    "    return pd.DataFrame(list, columns=col).sort_values('score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>400</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.793436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features  min_df  max_df     score\n",
       "0           200    0.05    0.80  0.793436\n",
       "1           300    0.05    0.90  0.793436\n",
       "2           500    0.05    0.95  0.793436\n",
       "3           500    0.05    0.90  0.793436\n",
       "4           500    0.05    0.80  0.793436\n",
       "5           400    0.05    0.95  0.793436\n",
       "6           400    0.05    0.90  0.793436\n",
       "7           200    0.05    0.90  0.793436\n",
       "8           300    0.05    0.95  0.793436\n",
       "9           400    0.05    0.80  0.793436"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = [200, 300, 400, 500]\n",
    "min_df = [0.05, 0.2, 0.3]\n",
    "max_df = [0.8, 0.9, 0.95]\n",
    "\n",
    "df_score = hiperparamentros_tfidfVectorizer(max_features, min_df, max_df)\n",
    "df_score.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível perceber que para os dez maiores valores de score calculado são para o min_df igual a 0.05, independente das variações dos outros hiperparâmetros. Então, vamos reajustar o valor de min_df e calcular novamente os valores de acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.839678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.839678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.839678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.839678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.839678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.839678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.837360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features  min_df  max_df     score\n",
       "0           500     0.0     0.9  0.842240\n",
       "1           500     0.0     0.8  0.842240\n",
       "2           500     0.0     0.7  0.842240\n",
       "3           400     0.0     0.7  0.839678\n",
       "4           300     0.0     0.8  0.839678\n",
       "5           400     0.0     0.9  0.839678\n",
       "6           400     0.0     0.8  0.839678\n",
       "7           300     0.0     0.9  0.839678\n",
       "8           300     0.0     0.7  0.839678\n",
       "9           200     0.0     0.8  0.837360"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = [200, 300, 400, 500]\n",
    "min_df = [0, 0.01, 0.05]\n",
    "max_df = [0.7, 0.8, 0.9]\n",
    "\n",
    "df_score = hiperparamentros_tfidfVectorizer(max_features, min_df, max_df)\n",
    "df_score.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, é possível visualizar as seguintes afirmações:\n",
    "- Quanto menor o valor min_df melhor é acuracia do modelo;\n",
    "- Quanto maior o valor max_features melhor é acuracia do modelo;\n",
    "- O valor de max_df não contribuiu para melhora da acurácia para esse conjunto de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.844802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.844802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.844802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.844314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.844314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>700</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.844314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.843948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.843948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>600</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.843948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.843582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.843582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.843582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>500</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.837970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.837970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_features  min_df  max_df     score\n",
       "0            700   0.000     0.9  0.844802\n",
       "1            700   0.000     0.8  0.844802\n",
       "2            700   0.000     0.7  0.844802\n",
       "3            700   0.001     0.9  0.844314\n",
       "4            700   0.001     0.8  0.844314\n",
       "5            700   0.001     0.7  0.844314\n",
       "6            600   0.001     0.8  0.843948\n",
       "7            600   0.001     0.9  0.843948\n",
       "8            600   0.001     0.7  0.843948\n",
       "9            600   0.000     0.7  0.843582\n",
       "10           600   0.000     0.8  0.843582\n",
       "11           600   0.000     0.9  0.843582\n",
       "12           500   0.000     0.8  0.842240\n",
       "13           500   0.000     0.7  0.842240\n",
       "14           500   0.001     0.9  0.842240\n",
       "15           500   0.001     0.8  0.842240\n",
       "16           500   0.001     0.7  0.842240\n",
       "17           500   0.000     0.9  0.842240\n",
       "18           500   0.005     0.9  0.837970\n",
       "19           600   0.005     0.7  0.837970"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = [500, 600, 700]\n",
    "min_df = [0, 0.001, 0.005]\n",
    "max_df = [0.7, 0.8, 0.9]\n",
    "\n",
    "df_score = hiperparamentros_tfidfVectorizer(max_features, min_df, max_df)\n",
    "df_score.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentar o valor de features para melhora do modelo de classificação não resultou em grande melhora da acurácia (score) do modelo, mas em contrapartida aumento sua complexidade. Então vamos escolher o melhor conjunto de hiperparâmetros para o max_features igual a 500. É possível perceber que nove diferentes combinações obtiveram um score de 0,84224. Logo, vamos escolher o maior valor de min_df e o menor valor de max_df para tentar tornar o modelo mais genérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.84224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.84224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.84224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.84224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.84224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.84224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>500</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.83797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>500</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.83797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>500</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.83797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_features  min_df  max_df    score\n",
       "12           500   0.000     0.8  0.84224\n",
       "13           500   0.000     0.7  0.84224\n",
       "14           500   0.001     0.9  0.84224\n",
       "15           500   0.001     0.8  0.84224\n",
       "16           500   0.001     0.7  0.84224\n",
       "17           500   0.000     0.9  0.84224\n",
       "18           500   0.005     0.9  0.83797\n",
       "22           500   0.005     0.8  0.83797\n",
       "23           500   0.005     0.7  0.83797"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score[df_score['max_features'] == 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores de hiperparâmetros selecionados:\n",
    "- max_features = 500\n",
    "- min_df = 0.001\n",
    "- max_df = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Definindo o Pipeline de trasformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo todas as trafomações regex para serem aplicadas ao pipeline\n",
    "regex_transformers = {\n",
    "    'datas': re_dates,\n",
    "    'valores_dinheiro': re_money,\n",
    "    'numeros': re_numbers,\n",
    "    'negacoes': re_negation,\n",
    "    'caracteres_especiais': re_special_chars,\n",
    "    'espacos_branco': re_whitespaces\n",
    "}\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500, min_df=0.001, max_df=0.7) \n",
    "\n",
    "# Criando o Pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('regex', RemoverRegex(regex_transformers)),\n",
    "    ('stopwords', RemoverStopwords(stopwords.words('portuguese'))),\n",
    "    ('normalization', ProcessoNormalizacao()),\n",
    "    ('stemming', ProcessoStemming(RSLPStemmer())),\n",
    "    ('text_features', ExtracaoFeatures(vectorizer))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Separando os dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dfinido X e y \n",
    "comentarios = dataset['review_comment_message'].dropna().index\n",
    "score = dataset['review_score'][comentarios].map({1: 'negativo', 2: 'negativo', 3: 'neutro', 4: 'positivo', 5: 'positivo'})\n",
    "\n",
    "# Dfinido X e y \n",
    "X = list(dataset['review_comment_message'][comentarios].values)\n",
    "y = score.values\n",
    "\n",
    "# Aplicando o pipeline\n",
    "X_processed = text_pipeline.fit_transform(X)\n",
    "\n",
    "\n",
    "# Separando os dados em treino e teste\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modelos de Classificação de Sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns algoritmos de regressão também podem ser utilizados para classificação (e vice-versa). A Regressão Logística (também chamada de Regressão Logit) é comumente utilizada para estimar a probabilidade de uma instância pertencer a uma determinada classe. Assim como um modelo de Regressão Linear, um modelo de Regressão Logística calcula uma soma ponderada das características de entrada (mais um termo de polarização), mas, em vez de gerar o resultado diretamente como o modelo de Regressão Linear, gera a logística desse resultado.\n",
    "\n",
    "O modelo de Regressão Logística pode ser generalizado para suportar múltiplas classes diretamente sem a necessidade de treinar e combinar vários classificadores binários. Isso é chamado Regressão Softmax, ou Regressão Logística Multinomial. A ideia é bem simples: quando dada uma instância x, o modelo de Regressão Softmax primeiro calcula uma pontuação sk(x) para cada classe k, então estima a probabilidade de cada classe aplicando a função softmax (também chamada exponencial normalizada) às pontuações.\n",
    "\n",
    "Uma vez calculada a pontuação de cada classe para a instância x, você pode estimar a probabilidade Pk de a instância pertencer à classe k ao executar as pontuações através da função softmax: ela calcula a exponencial de cada pontuação e a normaliza (dividindo pela soma de todas as exponenciais). Assim como o classificador de Regressão Logística, o classificador de Regressão Softmax prevê a classe com a maior probabilidade estimada (que é simplesmente a classe com a maior pontuação)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1. Recalculando a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos recalcular o score para o mesmo modelo que foi calculado a baseline, ou seja, iremos utilizar os mesmo hiperpâmetros para a LogisticRegression, mas iremos utilizar a base de dados tratas pelo Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.1.1. Acurácia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos a função cross_val_score() para avaliar o modelo LogisticRegression com a utilização da validação cruzada K-fold com três partes. Lembre-se de que a validação cruzada K-fold significa dividir o conjunto de treinamento em K-folds (neste caso, três), prever e avaliar as previsões em cada conjunto utilizando um modelo treinado em conjuntos restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:[0.84017864 0.84318032 0.84405886]\n",
      "Média: 0.8424726065841814\n",
      "Desvio Padrão: 0.001661260943955625\n"
     ]
    }
   ],
   "source": [
    "regressao_logistica = LogisticRegression(solver = \"saga\", multi_class='multinomial')\n",
    "scores = cross_val_score(regressao_logistica, X_processed, y, cv=3, scoring=\"accuracy\")\n",
    "print(f'Scores:{np.sort(scores)}')\n",
    "print(f'Média: {scores.mean()}')\n",
    "print(f'Desvio Padrão: {scores.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os valores dos scores obtido e com os valores da baseline antes do tratamento dos dados é possível perceber um ganho de 4.7% na acurácia do modelo utilizando os mesmos hiperparâmetros para o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.1.2. Matriz de confusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matriz de confusão é a forma mais simples de analisar o desempenho de um algoritmo de classificação, sendo base para os cáculo das métricas dela derivadas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=.20, random_state=42)\n",
    "y_pred = cross_val_predict(regressao_logistica, X_test, y_test, cv=3)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(conf_matrix, index=['Negativo', 'Neutro', 'Positivo'], columns=['Negativo', 'Neutro', 'Positivo'])\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"Blues\", fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada linha em uma matriz de confusão representa uma classe real, enquanto a coluna representa uma classe prevista. A partir da matriz de confusão podemos visualizar:\n",
    "- 1º linha da matriz considera reviews Negativos: 9436 reviews foram correamente classificados como negativos, enquanto 158 foram classificados como neutros e 1296 como positivos.\n",
    "- 2º linha da matriz considera reviews neutros: 213 reviews foram correamente classificados como neutros, enquanto 1656 foram classificados como negativos e 1688 como positivos.\n",
    "- 3º linha da matriz considera reviews Positivos: 24873 reviews foram correamente classificados como positivos, enquanto 1431 foram classificados como negativos e 226 como neutros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.1.3. Precisão e Revocação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A metrica precisão do classificador (precision_score) é a acurácia das previsões positivas. O melhor valor é 1 e o pior valor é 0.\n",
    "\n",
    "$$ precisão = \\frac {TP}{TP + FP} $$\n",
    "\n",
    "- TP: número de verdadeiros positivos\n",
    "- FP: número de falsos positivos\n",
    "\n",
    "A precisão é utilizada em conjunto com outra métrica chamada revocação (recall_score), também conhecida como sensibilidade ou taxa de verdadeiros positivos (TPR, do inglês): esta é a taxa de instâncias positivas que são corretamente detectadas pelo classificador.\n",
    "\n",
    "$$ revocacão = \\frac {TP}{TP + FN} $$\n",
    "\n",
    "- TP: número de verdadeiros positivos\n",
    "- FN: número de falsos negativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.1.4. Pontuação F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma simples de comparar dois classificadores é através da métrica chamada pontuação (F1). A pontuação F1 é a média harmônica da precisão e revocação. Enquanto a média regular trata igualmente todos os valores, a média harmônica dá muito mais peso aos valores mais baixos. Como resultado, o classificador só obterá uma pontuação F1 alta se a revocação e a precisão forem altas.\n",
    "\n",
    "$$F_1 = \\frac {2}{\\frac {1}{precisão} + \\frac {1}{revocacão}} = \\frac {precisão * revocacão} {precisão + revocacão} = \\frac {TP} {TP + \\frac {FN + FP} {2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.1.5. Analise precisão, revocação e pontuação (f1) para cada classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.84      0.79      2151\n",
      "      neutro       0.34      0.05      0.08       730\n",
      "    positivo       0.88      0.94      0.91      5315\n",
      "\n",
      "    accuracy                           0.83      8196\n",
      "   macro avg       0.66      0.61      0.59      8196\n",
      "weighted avg       0.80      0.83      0.80      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CR = classification_report(y_test, y_pred)\n",
    "print(CR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando as métricas para a classe \"neutro\" é possível confirmar de forma numérica o péssimo resultado de classificação para classe. As classes \"negativo\" e \"possitivo\" possui ótimas métricas, enquanto a classe \"neutro\" possui apenas 36% de precisão e 6% de revogação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2. Otimizando os hiperparamentors do modelo de LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(model, X_processed, y, tuned_parameters):\n",
    "\t\n",
    "\t# Estratégia para avaliar o desempenho do modelo de validação cruzada no conjunto de testes.\n",
    "\tscorer = make_scorer(f1_score, average = 'weighted')\n",
    "\t'''\n",
    "\t'weighted':\n",
    "\tCalcule as métricas para cada rótulo e encontre sua média ponderada pelo suporte \n",
    "\t(o número de instâncias verdadeiras para cada rótulo). Isso altera 'macro' para \n",
    "\tlevar em conta o desequilíbrio do rótulo; pode resultar em um F-score que não está \n",
    "\tentre precisão e recuperação.\n",
    "\t'''\n",
    "\n",
    "\n",
    "\tprint(f\"# Ajustando hiperparâmetros para {scorer}\")\n",
    "\tprint()\n",
    "\t\n",
    "\tclf = GridSearchCV(model, \n",
    "                        tuned_parameters, \n",
    "                        scoring=scorer,\n",
    "\t\t\t\t\t\tcv = KFold(n_splits = 3, shuffle=True))\n",
    "\t\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=.20, random_state=42)\n",
    "\n",
    "\tclf.fit(X_train, y_train)\n",
    "\n",
    "\tprint(\"Melhor conjunto de parâmetros encontrado: \")\n",
    "\tprint()\n",
    "\tprint(clf.best_params_)\n",
    "\tprint()\n",
    "\tprint(\"Pontuações de grade no conjunto de desenvolvimento:\")\n",
    "\tprint()\n",
    "\tmeans = clf.cv_results_[\"mean_test_score\"]\n",
    "\tstds = clf.cv_results_[\"std_test_score\"]\n",
    "\tfor mean, std, params in zip(means, stds, clf.cv_results_[\"params\"]):\n",
    "\t\tprint(f'{mean:.3f} (+/-{(std * 2):.3f}) for {params}')\n",
    "\tprint()\n",
    "\tprint(\"Relatório de classificação detalhado para o melhor modelo:\")\n",
    "\tprint()\n",
    "\ty_true, y_pred = y_test, clf.predict(X_test)\n",
    "\tprint(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 100, 'class_weight': None, 'max_iter': 250, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.797 (+/-0.004) for {'C': 100, 'class_weight': 'balanced', 'max_iter': 250, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "0.798 (+/-0.004) for {'C': 100, 'class_weight': 'balanced', 'max_iter': 250, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg'}\n",
      "0.724 (+/-0.076) for {'C': 100, 'class_weight': 'balanced', 'max_iter': 250, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'sag'}\n",
      "0.649 (+/-0.168) for {'C': 100, 'class_weight': 'balanced', 'max_iter': 250, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'saga'}\n",
      "0.816 (+/-0.002) for {'C': 100, 'class_weight': None, 'max_iter': 250, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "0.816 (+/-0.002) for {'C': 100, 'class_weight': None, 'max_iter': 250, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg'}\n",
      "0.816 (+/-0.002) for {'C': 100, 'class_weight': None, 'max_iter': 250, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'sag'}\n",
      "0.816 (+/-0.002) for {'C': 100, 'class_weight': None, 'max_iter': 250, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'saga'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.86      0.80      2151\n",
      "      neutro       0.35      0.08      0.13       730\n",
      "    positivo       0.89      0.93      0.91      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.62      0.61      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [100],\n",
    "    'multi_class': ['multinomial'],\n",
    "    'penalty': ['l2'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'random_state': [42],\n",
    "    'solver': ['lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "    'max_iter': [250] \n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "print_score(model, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos os solves ('lbfgs', 'newton-cg', 'sag', 'saga') obtiveram os mesmos valores de f1-score para 'class_weight' igual a None. É possível visualizar a ocorrência do erro de convergência para os conjuntos de parâmetros especificados. Mesmo com o erro, se compararmos o melhor modelo encontrado pelo GridSearchCV percebemos que houve em algumas métricas.\n",
    "\n",
    "Vamos verificar se aumentando o número máximo de iterações resolve o problema de convergencia do modelo, dado que os solves obtiveram os mesmos valores médios de f1-score, vamos utilizar o modelo 'lbfgs' e 'newton-cg'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 100, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.816 (+/-0.004) for {'C': 100, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "0.816 (+/-0.004) for {'C': 100, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg'}\n",
      "0.816 (+/-0.004) for {'C': 100, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'sag'}\n",
      "0.816 (+/-0.004) for {'C': 100, 'class_weight': None, 'max_iter': 1000, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "0.816 (+/-0.004) for {'C': 100, 'class_weight': None, 'max_iter': 1000, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'newton-cg'}\n",
      "0.816 (+/-0.004) for {'C': 100, 'class_weight': None, 'max_iter': 1000, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'sag'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.86      0.80      2151\n",
      "      neutro       0.35      0.08      0.13       730\n",
      "    positivo       0.89      0.93      0.91      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.62      0.61      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [100],\n",
    "    'multi_class': ['multinomial'],\n",
    "    'penalty': ['l2'],\n",
    "    'class_weight': [None],\n",
    "    'random_state': [42],\n",
    "    'solver': ['lbfgs', 'newton-cg', 'sag'],\n",
    "    'max_iter': [500, 1000] \n",
    "}\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "print_score(model, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O aumento do número máximo de iterações permitido corrigiu o erro de convergência do modelo, mas não resultou em melhores classificações de acordo com as métricas. Então, vamos adotar o modelo 'lbfgs' como sendo o solver para a LogisticRegression. Por fim, vamos variar o hiperparâmentro 'C' (Inverse of regularization strength):   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Brothers\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 1000, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.816 (+/-0.005) for {'C': 500, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "0.816 (+/-0.005) for {'C': 1000, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "0.816 (+/-0.005) for {'C': 10000, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.86      0.80      2151\n",
      "      neutro       0.35      0.08      0.13       730\n",
      "    positivo       0.89      0.93      0.91      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.62      0.61      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [500, 1000, 10000],\n",
    "    'multi_class': ['multinomial'],\n",
    "    'penalty': ['l2'],\n",
    "    'class_weight': [None],\n",
    "    'random_state': [42],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [500] \n",
    "}\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "print_score(model, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alterar o parâmetro 'C' não resultou em melhora do modelo e ainda gerou erro de convergência nos modelos testados. Então vamos assumir o seguinte conjunto de hiperparâmetros para o modelo de LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 100, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.817 (+/-0.012) for {'C': 100, 'class_weight': None, 'max_iter': 500, 'multi_class': 'multinomial', 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.86      0.80      2151\n",
      "      neutro       0.35      0.08      0.13       730\n",
      "    positivo       0.89      0.93      0.91      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.62      0.61      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n",
      "Tempo de execução: 1.426566473642985min\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [100],\n",
    "    'multi_class': ['multinomial'],\n",
    "    'penalty': ['l2'],\n",
    "    'class_weight': [None],\n",
    "    'random_state': [42],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [500] \n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "incial = time()\n",
    "print_score(model, X_processed, y, tuned_parameters)\n",
    "final = time()\n",
    "print(f'Tempo de execução: {(final - incial) / 60}min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível perceber que para classe de pior desempenho é a 'neutro', onde apenas 8% de revocação e 35% de precisão. A pequena quantidade de amostra da classe 'neutro' faz com que as métricas que são analisadas de formas gerais não caia tanto de valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. SVM (Support Vector Machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma Máquina de Vetores de Suporte (SVM) é um modelo muito poderoso e versátil de Aprendizado de Máquina capaz de realizar classificações lineares ou não lineares, de regressão e até mesmo detecção de outliers. As SVM são particularmente adequadas para a classificação de conjuntos de dados complexos. Dentro da modulo SVM iremos utilizar a classe SVC (C-Support Vector Classification.), no qual o suporte multiclasse é tratado de acordo com um esquema de um contra um.\n",
    "\n",
    "Hiperparâmetro:\n",
    "- C: Parâmetro de regularização. Um valor menor de C leva a uma via mais larga, mas com mais violações das margens.\n",
    "- kernel: Especifica o tipo de kernel a ser usado no algoritmo. \n",
    "- coef0: controla o quanto o modelo é influenciado por polinômios de alto grau versus polinômios de baixo grau. Só é significativo em 'poli' e 'sigmóide'.\n",
    "- gamma: Coeficiente de kernel para 'rbf', 'poli' e 'sigmoid'.\n",
    "    - Se gamma='scale'(padrão) for passado, ele usará 1 / (n_features * X.var()) como valor de gama,\n",
    "    - Se 'auto', usa 1 / n_features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.819 (+/-0.010) for {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.678 (+/-0.023) for {'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.75      0.89      0.81      2151\n",
      "      neutro       0.27      0.02      0.04       730\n",
      "    positivo       0.89      0.94      0.92      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.64      0.62      0.59      8196\n",
      "weighted avg       0.80      0.84      0.81      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [1.0],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': ['scale', 'auto'] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em uma primeira analise com o classificador SVC houve uma pequena melhora na classificação das classes 'negativo' e 'positivo', enquanto a classe 'neutro' piorou significativamente, se comparada com o melhor modelo de LogisticRegression. O custo computacional para o classificador SVC foi muito superior. A classe 'neutra' se manteve como a pior classe na classificação dos reveiws, se comparado com o modelo de LogisticRegression, teve uma queda de 0.09 em f1-score e 0.06 no recall. \n",
    "\n",
    "Iremos verificar o aumento do valor de 'C' e a definição do valor de 'gama' manualmente. O alto valor de C faz o classificador possuir menos violações na margem, mas fica com uma margem menor. Aumentar ‘gamma’ estreitará a curva em forma de sino, e como resultado cada raio de influência da instância será menor: mexer ao redor de instâncias individuais torna a fronteira de decisão mais irregular. Por outro lado, um pequeno valor de ‘gamma’ torna a curva em forma de sino mais ampla, de modo que as instâncias ficam com um maior raio de influência e o limite de decisão fica mais suave.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.807 (+/-0.003) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.580 (+/-0.014) for {'C': 1.0, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.825 (+/-0.003) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.586 (+/-0.012) for {'C': 100, 'gamma': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.87      0.81      2151\n",
      "      neutro       0.32      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.92      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.63      0.63      8196\n",
      "weighted avg       0.81      0.84      0.82      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [1.0, 100],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1, 10] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variação dos hiperparâmetros resultou em uma excelente melhora no modelo de classificação em todas as classes chegando a superar o melhor modelo de LogisticRegression. Em especial houve melhora na classe 'neutro', nas métricas recall e f1-score.\n",
    "\n",
    "Como o melhor modelo encontrado possui um valor alto de do hiperparâmetros 'C', vamos verificar se aumentando ainda mais seu valor melhora o resultado da classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 200, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.823 (+/-0.006) for {'C': 200, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.820 (+/-0.006) for {'C': 300, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.84      0.80      2151\n",
      "      neutro       0.25      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.91      5315\n",
      "\n",
      "    accuracy                           0.83      8196\n",
      "   macro avg       0.63      0.62      0.62      8196\n",
      "weighted avg       0.80      0.83      0.81      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [200, 300],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O grande aumento do hiperparâmetro 'C' não resultou em melhora do modelo, mas resultou em um valor de f1-score bastante próximo do melhor modelo encontrodado. Então vamos verificar um valor de 'C' mais próximo de 100 (valor do melhor classificado):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 125, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.823 (+/-0.005) for {'C': 125, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.821 (+/-0.004) for {'C': 125, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.823 (+/-0.005) for {'C': 175, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.821 (+/-0.004) for {'C': 175, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.86      0.81      2151\n",
      "      neutro       0.30      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.91      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.65      0.63      0.63      8196\n",
      "weighted avg       0.81      0.84      0.82      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [125, 175],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1, 1] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 110, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.823 (+/-0.001) for {'C': 110, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.823 (+/-0.002) for {'C': 112, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.87      0.81      2151\n",
      "      neutro       0.32      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.92      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.63      0.63      8196\n",
      "weighted avg       0.81      0.84      0.82      8196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [110, 112],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados obtidos foram bastante similar com o modelo de parâmentros igual {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}. O valor de f1-score foi menor que 0.825 (+/-0.003), mas o desvio padrão foi menor (+/-0.001) para os três valores calculados para Cross-Validation.\n",
    "\n",
    "O melhor modelo para o SVC selecionado será:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajustando hiperparâmetros para make_scorer(f1_score, average=weighted)\n",
      "\n",
      "Melhor conjunto de parâmetros encontrado: \n",
      "\n",
      "{'C': 110, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Pontuações de grade no conjunto de desenvolvimento:\n",
      "\n",
      "0.824 (+/-0.003) for {'C': 110, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Relatório de classificação detalhado para o melhor modelo:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.76      0.87      0.81      2151\n",
      "      neutro       0.32      0.10      0.15       730\n",
      "    positivo       0.90      0.93      0.92      5315\n",
      "\n",
      "    accuracy                           0.84      8196\n",
      "   macro avg       0.66      0.63      0.63      8196\n",
      "weighted avg       0.81      0.84      0.82      8196\n",
      "\n",
      "Tempo de execução: 46.78752770423889min\n"
     ]
    }
   ],
   "source": [
    "# Hiperparâmentros\n",
    "tuned_parameters = {\n",
    "    'C': [110],\n",
    "    'kernel' : ['rbf'],\n",
    "    'gamma': [0.1] \n",
    "}\n",
    "\n",
    "model_SVC = SVC()\n",
    "incial = time()\n",
    "print_score(model_SVC, X_processed, y, tuned_parameters)\n",
    "final = time()\n",
    "print(f'Tempo de execução: {(final - incial) / 60}min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12fb55c19b53ac09035d9d6bd41a050fcb0becbe4846579be579fa8f11e9abb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
